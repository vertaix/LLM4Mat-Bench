# LLM4Mat-Bench
LLM4Mat-Bench is the largest benchmark to date for evaluating the performance of large language models (LLMs) for materials property prediction.

<p align="center" width="100%">
    <img src="figures/llm4mat-bench_stats.png" alt="image" width="50%" height="auto">
    <br>
    <em>LLM4Mat-Bench Statistics. *https://www.snumat.com/apis</em>
</p>

## Data Availability
The data collected for the LLM4Mat-Bench can be found [here](https://drive.google.com/drive/folders/1HpGhuNHG4EQCQMZaKPwEQNH9stJKw-ht). Each dataset includes a fixed train/validation/test split for reproducibility and fair model comparison. The data **LICENSE** belongs to the original creators of each dataset/database.

## TODOs
- Adding the link to the paper
- Adding the detailed guidelines to run the models we evaluated on LLM4Mat-Bench
- Adding how to cite LLM4Mat-Bench
- Adding the leaderboard (Optional)